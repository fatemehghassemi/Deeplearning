{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "ex2-conv-cifar10-in-colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatemehghassemi/Deeplearning/blob/main/homework/ex2-conv-cifar10-in-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpG9pOvq1hF6"
      },
      "source": [
        "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
        "\n",
        "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 2: طبقه بندی تصاویر Cifar10 با شبکه های کانولوشنالی روی googleColab</div></center></h1>\n",
        "\n",
        "[![Run in Google Colab](https://github.com/alireza-akhavan/SRU-deeplearning-workshop/blob/master/homework/images/colab.png?raw=1)](https://colab.research.google.com/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/homework/ex2-conv-cifar10-in-colab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLK6KZ3-1hF-"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">صورت مساله</div>\n",
        "\n",
        "\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "با شبکه های کانولوشنالی آشنا شدیم<br>\n",
        "توصیه می‌شود حتما بعد از تمرین اول این تمرین را حل کنید و قبل از این تمرین نوت بوک زیر را  مرور کنید:\n",
        "</div>\n",
        "\n",
        "[06_ConvolutionalNeuralNetwork-Hoda-Keras.ipynb ](https://nbviewer.jupyter.org/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/06_ConvolutionalNeuralNetwork-Hoda-Keras.ipynb)\n",
        "\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "در این تمرین از مجموعه داده تصویری cifar10 استفاده خواهیم کرد. \n",
        "<br>\n",
        "خیلی از اوقات ممکنه دسترسی به GPU نداشته باشیم. حخوشبختانه سرویس های آنلاین و رایگانی هستند که توان محاسباتی رایگان در اختیارمان میگذراند. در این تمرین از شما خواسته شده که این نوت بوک را در گوگل کولب اجرا کنید.\n",
        "<br>\n",
        " قبلا در مورد گوگل کولب دو پست آموزشی نوشته شده است که در صورت تمایل به کسب اطلاعات بیشتر میتوانید بخوانید.\n",
        "    اما برای اجرا این تمرین نیازی به این جزئیات نخواهید داشت.\n",
        "</div>\n",
        "\n",
        "[آشنایی با سرویس ابری Google Colab ](http://blog.class.vision/1397/02/google-colab/)\n",
        "\n",
        "[اتصال مستقیم سرویس کولب (Google Colab) به درایو (Google Drive) از طریق فایل سیستم FUSE ](http://blog.class.vision/1397/04/%D8%A7%D8%AA%D8%B5%D8%A7%D9%84-%D9%85%D8%B3%D8%AA%D9%82%DB%8C%D9%85-%D8%B3%D8%B1%D9%88%DB%8C%D8%B3-%DA%A9%D9%88%D9%84%D8%A8-google-colab-%D8%A8%D9%87-%D8%AF%D8%B1%D8%A7%DB%8C%D9%88-google-drive/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwuZKlCN1hGA"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">لود کتابخانه های مورد نیاز </div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "کتابخانه های مورد نیاز این تمرین لود شده اند\n",
        "<br>\n",
        "در صورت نیاز میتوانید کتابخانه های بیشتری لود کنید:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fP4rTb21hGA"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq0vScSJ1hGD"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">مجموعه داده ی Cifar10 </div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "<br>\n",
        "این مجموعه داده تصاویر رنگی در اندازه ی 32 در 32 و در 10 کلاس مختلف شامل ماشین، کامیون، اسب و ... است که در چارچوب کراس موجود است و از همان استفاده میکنیم.\n",
        "<br>\n",
        "اطلاعات بیشتر در مورد این مجموعه داده را از سایت این مجموعه داده میتوانید مطالعه کنید:\n",
        "<br>\n",
        "</div>\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1dxBqJk1hGD"
      },
      "source": [
        "(x_train_original, y_train_original), (x_test_original, y_test_original) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tckffizH1hGE"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">نگاهی به مجموعه داده بیندازیم...</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "در زیر تصویری که در اندیس 7-ام این مجموعه داده قرار دارد را مشاهده می‌کنیم. این شماره را را به دلخوه عوض کنید و چند تصویر دیگر این مجموعه داده را ببینید.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPB-oAEL1hGF",
        "outputId": "0020a2c8-8f3b-499f-ccbd-4f13f552d3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.imshow(x_train_original[7])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9a366129d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFBcmZB41hGF"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 1:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "ماتریس های تصویر را تبدیل به نوع داده ای float32 کنید و مقادیر پیکسل ها را نرمال کنید و بین 0 و 1 بیاورید.\n",
        "<br>\n",
        "<b>راهنمایی: </b>\n",
        "شما باید متد astype را صدا بزنید و در نهایت مقادیر پیکسل ها را تقسیم بر 255 کنید.</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buG0Nj3B1hGG"
      },
      "source": [
        "# Preprocess input data\n",
        "''' 3.1: input data in numpy array format'''\n",
        "x_train = np.array(x_train_original)\n",
        "x_test = np.array(x_test_original)\n",
        "'''3.2 normalize our data values to the range [0, 1]'''\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1CfYVam1hGH"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 2:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "همان طور که میبینید لیبل ها از نوع عددی هستند. آن ها را تبدیل به فرمت one-hot کنید.<br>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OPytLBu1hGH"
      },
      "source": [
        "<hr>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "تعدادی از لیبل ها قبل از تبدیل به فرمت one-hot:</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLpO2l231hGH",
        "outputId": "b7e90589-93fa-4790-bba3-78c40bb87c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_original[0:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [3]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewl3sDnj1hGI"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test_original, num_classes=10) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h47K54N21hGI"
      },
      "source": [
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "تعدادی از لیبل ها بعد از تبدیل به فرمت one-hot:</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heFH94DU1hGJ",
        "outputId": "a0f42cc3-69e9-4cf8-f60a-2a2ccb324b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train[0:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVzlf5q81hGJ"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 3:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "یک شبکه کانولوشنالی با معماری زیر بسازید:\n",
        "<ul>\n",
        "    <li>\n",
        "    یک لایه کانولوشنی با32 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
        "    </li>\n",
        "    <li>\n",
        "    لایه ی pooling با pool_size=(2,2)\n",
        "    </li>\n",
        "    <li>\n",
        "    یک لایه کانولوشنی با32 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
        "    </li>\n",
        "    <li>\n",
        "    لایه ی pooling با pool_size=(2,2)\n",
        "    </li>\n",
        "    <li>\n",
        "    یک لایه کانولوشنی با64 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
        "    </li>\n",
        "    <li>\n",
        "    لایه ی pooling با pool_size=(2,2)\n",
        "    </li>\n",
        "    <li>\n",
        "    استفاده از لایه ی Flatten() . به نظرتون چرا؟\n",
        "    </li>    \n",
        "    <li>\n",
        "    یک لایه Dropout با ترخ 0.5.\n",
        "    </li>\n",
        "    <li>\n",
        "    یک لایه softmax برای احتمالات خروجی. به نظرتون این لایه چند نوران میخواهد؟\n",
        "    </li>    \n",
        " \n",
        "</ul>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBivddXd1hGK"
      },
      "source": [
        "from keras import layers\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQZt0a2k1hGK"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 4:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "مدل را کامپایل کنید و به عنوان optimizer متغیر opt_rms به تابع ارسال کنید. </div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REXDOHTV1hGL",
        "outputId": "b422db3f-30e8-4d6f-cb02-0195ae8bc178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt_rms = keras.optimizers.RMSprop(lr=0.001,decay=1e-6)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHrFOEYX2fv5",
        "outputId": "c7053e62-095b-4ff6-987e-010d1003f7db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(lr=0.001,decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2yUkGSr1hGL"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 5:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "با فراخوانی متد fit روی مدل آن را آموزش بدهید. برای سادگی25 ایپاک با سایز بچ 64 بزنید. \n",
        "    <br>\n",
        " به عنوان دیتای validation نیز x_test و y_test را ارسال کنید که در هر سری کارایی روی داده های تست اعلام شود.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yji0opzw1hGM",
        "outputId": "9086c1ca-065c-4925-888e-273e6b6e8307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "          epochs=25, batch_size=64, validation_data = (x_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c2dab7f662e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x_train, y_train,\n\u001b[0;32m----> 2\u001b[0;31m           epochs=25, batch_size=64, validation_data = (x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:248 assert_input_compatibility  *\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape (None, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRqLuZRL1hGN"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 6:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "شبکه و هایپرپارامترهای این شبکه را به هر نحوی دوست دارید تغییر دهید تا دقت روی دادگان تست را به حداکثر برسانید.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRc37ynG1hGN"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br>پنج شنبه، ۱۸ و ۲۵ بهمن ۱۳۹۷<br>\n",
        "</div>\n",
        "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb1DCpJ61hGO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}